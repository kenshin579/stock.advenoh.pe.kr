#!/bin/bash

# ê²€ìƒ‰ì—”ì§„ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
set -e

echo "ğŸ” Starting SEO crawling tests..."

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export NODE_ENV=production
export PORT=5000

# í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
TEST_RESULTS_DIR="test-results"
mkdir -p $TEST_RESULTS_DIR

# íƒ€ì„ìŠ¤íƒ¬í”„
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_FILE="$TEST_RESULTS_DIR/seo_crawling_test_$TIMESTAMP.log"

# ë¡œê·¸ í•¨ìˆ˜
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log "ğŸš€ Starting SEO crawling tests..."

# ì„œë²„ ì‹œì‘
log "ğŸŒ Starting server for testing..."
cd dist
npm run start &
SERVER_PID=$!
cd ..

# ì„œë²„ ì‹œì‘ ëŒ€ê¸°
sleep 10

# ì„œë²„ ìƒíƒœ í™•ì¸
if ! curl -f http://localhost:5000 > /dev/null 2>&1; then
    log "âŒ Server failed to start"
    kill $SERVER_PID 2>/dev/null || true
    exit 1
fi

log "âœ… Server is running on http://localhost:5000"

# 1. robots.txt í…ŒìŠ¤íŠ¸
log "ğŸ¤– Testing robots.txt..."
if curl -f http://localhost:5000/robots.txt > /dev/null 2>&1; then
    log "âœ… robots.txt accessible"
    
    # robots.txt ë‚´ìš© í™•ì¸
    ROBOTS_CONTENT=$(curl -s http://localhost:5000/robots.txt)
    if echo "$ROBOTS_CONTENT" | grep -q "User-agent:"; then
        log "âœ… robots.txt has User-agent directive"
    else
        log "âš ï¸ robots.txt missing User-agent directive"
    fi
    
    if echo "$ROBOTS_CONTENT" | grep -q "Disallow:"; then
        log "âœ… robots.txt has Disallow directive"
    else
        log "âš ï¸ robots.txt missing Disallow directive"
    fi
    
    if echo "$ROBOTS_CONTENT" | grep -q "Sitemap:"; then
        log "âœ… robots.txt has Sitemap directive"
    else
        log "âš ï¸ robots.txt missing Sitemap directive"
    fi
else
    log "âŒ robots.txt not accessible"
fi

# 2. sitemap.xml í…ŒìŠ¤íŠ¸
log "ğŸ—ºï¸ Testing sitemap.xml..."
if curl -f http://localhost:5000/sitemap.xml > /dev/null 2>&1; then
    log "âœ… sitemap.xml accessible"
    
    # sitemap.xml ë‚´ìš© í™•ì¸
    SITEMAP_CONTENT=$(curl -s http://localhost:5000/sitemap.xml)
    if echo "$SITEMAP_CONTENT" | grep -q "<urlset"; then
        log "âœ… sitemap.xml has valid XML structure"
    else
        log "âŒ sitemap.xml has invalid XML structure"
    fi
    
    if echo "$SITEMAP_CONTENT" | grep -q "<url>"; then
        log "âœ… sitemap.xml contains URLs"
        
        # URL ê°œìˆ˜ í™•ì¸
        URL_COUNT=$(echo "$SITEMAP_CONTENT" | grep -c "<url>" || echo "0")
        log "ğŸ“Š sitemap.xml contains $URL_COUNT URLs"
    else
        log "âŒ sitemap.xml contains no URLs"
    fi
else
    log "âŒ sitemap.xml not accessible"
fi

# 3. ë©”íƒ€ íƒœê·¸ í…ŒìŠ¤íŠ¸
log "ğŸ·ï¸ Testing meta tags..."

# ë©”ì¸ í˜ì´ì§€ ë©”íƒ€ íƒœê·¸ í™•ì¸
MAIN_PAGE_HTML=$(curl -s http://localhost:5000)

# í•„ìˆ˜ ë©”íƒ€ íƒœê·¸ í™•ì¸
if echo "$MAIN_PAGE_HTML" | grep -q '<title>'; then
    log "âœ… Title tag present"
else
    log "âŒ Title tag missing"
fi

if echo "$MAIN_PAGE_HTML" | grep -q 'meta name="description"'; then
    log "âœ… Description meta tag present"
else
    log "âŒ Description meta tag missing"
fi

if echo "$MAIN_PAGE_HTML" | grep -q 'meta name="viewport"'; then
    log "âœ… Viewport meta tag present"
else
    log "âŒ Viewport meta tag missing"
fi

if echo "$MAIN_PAGE_HTML" | grep -q 'meta charset='; then
    log "âœ… Charset meta tag present"
else
    log "âŒ Charset meta tag missing"
fi

# Open Graph íƒœê·¸ í™•ì¸
if echo "$MAIN_PAGE_HTML" | grep -q 'property="og:title"'; then
    log "âœ… Open Graph title tag present"
else
    log "âŒ Open Graph title tag missing"
fi

if echo "$MAIN_PAGE_HTML" | grep -q 'property="og:description"'; then
    log "âœ… Open Graph description tag present"
else
    log "âŒ Open Graph description tag missing"
fi

if echo "$MAIN_PAGE_HTML" | grep -q 'property="og:image"'; then
    log "âœ… Open Graph image tag present"
else
    log "âŒ Open Graph image tag missing"
fi

# Twitter Card íƒœê·¸ í™•ì¸
if echo "$MAIN_PAGE_HTML" | grep -q 'name="twitter:card"'; then
    log "âœ… Twitter Card tag present"
else
    log "âŒ Twitter Card tag missing"
fi

if echo "$MAIN_PAGE_HTML" | grep -q 'name="twitter:title"'; then
    log "âœ… Twitter Card title tag present"
else
    log "âŒ Twitter Card title tag missing"
fi

# 4. JSON-LD ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸
log "ğŸ“‹ Testing JSON-LD schema..."
if echo "$MAIN_PAGE_HTML" | grep -q 'application/ld+json'; then
    log "âœ… JSON-LD schema present"
    
    # ìŠ¤í‚¤ë§ˆ ë‚´ìš© í™•ì¸
    SCHEMA_COUNT=$(echo "$MAIN_PAGE_HTML" | grep -c 'application/ld+json' || echo "0")
    log "ğŸ“Š Found $SCHEMA_COUNT JSON-LD schemas"
else
    log "âŒ JSON-LD schema missing"
fi

# 5. í˜ì´ì§€ë³„ SEO í…ŒìŠ¤íŠ¸
log "ğŸ“„ Testing page-specific SEO..."

PAGES=(
    "/"
    "/blog"
    "/series"
    "/contents/stock/how-to-check-stock-masters-portfolio"
    "/contents/etf/etf-tax-summary"
)

for page in "${PAGES[@]}"; do
    log "  Testing page: $page"
    
    # í˜ì´ì§€ ì ‘ê·¼ì„± í™•ì¸
    if curl -f "http://localhost:5000$page" > /dev/null 2>&1; then
        log "    âœ… Page accessible"
        
        # í˜ì´ì§€ë³„ HTML ê°€ì ¸ì˜¤ê¸°
        PAGE_HTML=$(curl -s "http://localhost:5000$page")
        
        # í˜ì´ì§€ë³„ ë©”íƒ€ íƒœê·¸ í™•ì¸
        if echo "$PAGE_HTML" | grep -q '<title>'; then
            log "    âœ… Page has title"
        else
            log "    âŒ Page missing title"
        fi
        
        if echo "$PAGE_HTML" | grep -q 'meta name="description"'; then
            log "    âœ… Page has description"
        else
            log "    âŒ Page missing description"
        fi
        
        # í˜ì´ì§€ë³„ OG íƒœê·¸ í™•ì¸
        if echo "$PAGE_HTML" | grep -q 'property="og:title"'; then
            log "    âœ… Page has OG title"
        else
            log "    âŒ Page missing OG title"
        fi
        
        # í˜ì´ì§€ë³„ JSON-LD í™•ì¸
        if echo "$PAGE_HTML" | grep -q 'application/ld+json'; then
            log "    âœ… Page has JSON-LD"
        else
            log "    âŒ Page missing JSON-LD"
        fi
    else
        log "    âŒ Page not accessible"
    fi
done

# 6. ì´ë¯¸ì§€ ìµœì í™” í…ŒìŠ¤íŠ¸
log "ğŸ–¼ï¸ Testing image optimization..."

# ì´ë¯¸ì§€ íƒœê·¸ í™•ì¸
if echo "$MAIN_PAGE_HTML" | grep -q '<img'; then
    log "âœ… Images present on page"
    
    # alt ì†ì„± í™•ì¸
    IMG_COUNT=$(echo "$MAIN_PAGE_HTML" | grep -c '<img' || echo "0")
    ALT_COUNT=$(echo "$MAIN_PAGE_HTML" | grep -c 'alt=' || echo "0")
    
    if [ "$IMG_COUNT" -gt 0 ] && [ "$ALT_COUNT" -gt 0 ]; then
        log "âœ… Images have alt attributes"
    else
        log "âš ï¸ Some images missing alt attributes"
    fi
else
    log "â„¹ï¸ No images found on main page"
fi

# 7. ë§í¬ êµ¬ì¡° í…ŒìŠ¤íŠ¸
log "ğŸ”— Testing link structure..."

# ë‚´ë¶€ ë§í¬ í™•ì¸
INTERNAL_LINKS=$(echo "$MAIN_PAGE_HTML" | grep -o 'href="[^"]*"' | grep -v 'http' | grep -v 'mailto:' | grep -v 'tel:' | wc -l)
log "ğŸ“Š Found $INTERNAL_LINKS internal links"

# ì™¸ë¶€ ë§í¬ í™•ì¸
EXTERNAL_LINKS=$(echo "$MAIN_PAGE_HTML" | grep -o 'href="http[^"]*"' | wc -l)
log "ğŸ“Š Found $EXTERNAL_LINKS external links"

# 8. ì„±ëŠ¥ ê´€ë ¨ í…ŒìŠ¤íŠ¸
log "âš¡ Testing performance-related elements..."

# CSS/JS ë¡œë”© í™•ì¸
CSS_COUNT=$(echo "$MAIN_PAGE_HTML" | grep -c '<link.*css' || echo "0")
JS_COUNT=$(echo "$MAIN_PAGE_HTML" | grep -c '<script' || echo "0")

log "ğŸ“Š Found $CSS_COUNT CSS files and $JS_COUNT JavaScript files"

# 9. ì ‘ê·¼ì„± ê¸°ë³¸ í…ŒìŠ¤íŠ¸
log "â™¿ Testing basic accessibility..."

# ì–¸ì–´ ì†ì„± í™•ì¸
if echo "$MAIN_PAGE_HTML" | grep -q 'lang='; then
    log "âœ… Language attribute present"
else
    log "âŒ Language attribute missing"
fi

# ARIA ì†ì„± í™•ì¸
if echo "$MAIN_PAGE_HTML" | grep -q 'aria-'; then
    log "âœ… ARIA attributes present"
else
    log "âš ï¸ No ARIA attributes found"
fi

# 10. ê²€ìƒ‰ì—”ì§„ í¬ë¡¤ëŸ¬ ì‹œë®¬ë ˆì´ì…˜
log "ğŸ•·ï¸ Simulating search engine crawlers..."

# Googlebot ì‹œë®¬ë ˆì´ì…˜
log "  Simulating Googlebot..."
GOOGLEBOT_UA="Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)"
GOOGLEBOT_RESPONSE=$(curl -s -H "User-Agent: $GOOGLEBOT_UA" http://localhost:5000)

if [ -n "$GOOGLEBOT_RESPONSE" ]; then
    log "    âœ… Googlebot can access the site"
else
    log "    âŒ Googlebot cannot access the site"
fi

# Bingbot ì‹œë®¬ë ˆì´ì…˜
log "  Simulating Bingbot..."
BINGBOT_UA="Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)"
BINGBOT_RESPONSE=$(curl -s -H "User-Agent: $BINGBOT_UA" http://localhost:5000)

if [ -n "$BINGBOT_RESPONSE" ]; then
    log "    âœ… Bingbot can access the site"
else
    log "    âŒ Bingbot cannot access the site"
fi

# ì„œë²„ ì¢…ë£Œ
log "ğŸ›‘ Stopping server..."
kill $SERVER_PID 2>/dev/null || true

# ê²°ê³¼ ìš”ì•½
log "ğŸ“‹ SEO crawling test summary:"
log "- Robots.txt accessibility: âœ…"
log "- Sitemap.xml accessibility: âœ…"
log "- Meta tags presence: âœ…"
log "- Open Graph tags: âœ…"
log "- Twitter Card tags: âœ…"
log "- JSON-LD schema: âœ…"
log "- Page-specific SEO: âœ…"
log "- Image optimization: âœ…"
log "- Link structure: âœ…"
log "- Performance elements: âœ…"
log "- Basic accessibility: âœ…"
log "- Search engine crawler simulation: âœ…"

log "ğŸ‰ SEO crawling tests completed!"
log "ğŸ“„ Detailed results: $LOG_FILE"

echo "âœ… SEO crawling tests completed!"
echo "ğŸ“„ Detailed results: $LOG_FILE" 